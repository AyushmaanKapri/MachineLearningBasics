{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3ae5eed",
   "metadata": {},
   "source": [
    "## Reading Data from Various Sources Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0463a118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_name</th>\n",
       "      <th>email</th>\n",
       "      <th>job_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "      <td>james@gmail.com</td>\n",
       "      <td>Team Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michael</td>\n",
       "      <td>michael@gmail.com</td>\n",
       "      <td>Senior Developer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_name              email       job_profile\n",
       "0         James    james@gmail.com         Team Lead\n",
       "1       Michael  michael@gmail.com  Senior Developer"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "json_data ='''\n",
    "[\n",
    " {\"employee_name\": \"James\", \"email\": \"james@gmail.com\", \"job_profile\": \"Team Lead\"},\n",
    "  {\"employee_name\": \"Michael\", \"email\": \"michael@gmail.com\", \"job_profile\": \"Senior Developer\"}\n",
    "]'''\n",
    "df=pd.read_json(StringIO(json_data))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0209fb47",
   "metadata": {},
   "source": [
    "Converting Data frame Back TO JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85c9f30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"employee_name\":{\"0\":\"James\",\"1\":\"Michael\"},\"email\":{\"0\":\"james@gmail.com\",\"1\":\"michael@gmail.com\"},\"job_profile\":{\"0\":\"Team Lead\",\"1\":\"Senior Developer\"}}\n"
     ]
    }
   ],
   "source": [
    "json_default = df.to_json()\n",
    "print(json_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f889e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"employee_name\":\"James\",\"email\":\"james@gmail.com\",\"job_profile\":\"Team Lead\"},{\"employee_name\":\"Michael\",\"email\":\"michael@gmail.com\",\"job_profile\":\"Senior Developer\"}]\n"
     ]
    }
   ],
   "source": [
    "json_records = df.to_json(orient='records')\n",
    "print(json_records)\n",
    "\n",
    "# orient='records proovides a list type format where each element corresponds to a row in  the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461480a1",
   "metadata": {},
   "source": [
    "Reading CSV DATA FROM URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60cc89db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
      "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
      "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
      "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
      "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
      "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
      "\n",
      "     13  \n",
      "0  1065  \n",
      "1  1050  \n",
      "2  1185  \n",
      "3  1480  \n",
      "4   735  \n"
     ]
    }
   ],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "df_csv = pd.read_csv(url, header=None)\n",
    "print(df_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbc683e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.to_csv('wine.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "348d1617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading lxml-6.0.2-cp314-cp314-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting html5lib\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: six>=1.9 in r:\\ml\\python\\venv\\lib\\site-packages (from html5lib) (1.17.0)\n",
      "Collecting webencodings (from html5lib)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4)\n",
      "  Using cached soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from beautifulsoup4)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Downloading lxml-6.0.2-cp314-cp314-win_amd64.whl (4.1 MB)\n",
      "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/4.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.8/4.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.8/4.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 1.0/4.1 MB 918.1 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 1.3/4.1 MB 984.9 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 1.3/4.1 MB 984.9 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 1.6/4.1 MB 929.8 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 1.8/4.1 MB 931.4 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 1.8/4.1 MB 931.4 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 2.1/4.1 MB 916.1 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 2.1/4.1 MB 916.1 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 2.4/4.1 MB 863.5 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 2.4/4.1 MB 863.5 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 2.6/4.1 MB 836.2 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 2.6/4.1 MB 836.2 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 2.9/4.1 MB 821.5 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 3.1/4.1 MB 815.0 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 3.1/4.1 MB 815.0 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 3.4/4.1 MB 796.7 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.4/4.1 MB 796.7 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.7/4.1 MB 781.7 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.7/4.1 MB 781.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.9/4.1 MB 768.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.1/4.1 MB 776.4 kB/s  0:00:05\n",
      "Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "Using cached soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, typing-extensions, soupsieve, lxml, html5lib, beautifulsoup4\n",
      "\n",
      "   ---------------------------------------- 0/6 [webencodings]\n",
      "   ------------- -------------------------- 2/6 [soupsieve]\n",
      "   ------------- -------------------------- 2/6 [soupsieve]\n",
      "   -------------------- ------------------- 3/6 [lxml]\n",
      "   -------------------- ------------------- 3/6 [lxml]\n",
      "   -------------------- ------------------- 3/6 [lxml]\n",
      "   -------------------- ------------------- 3/6 [lxml]\n",
      "   -------------------- ------------------- 3/6 [lxml]\n",
      "   -------------------------- ------------- 4/6 [html5lib]\n",
      "   -------------------------- ------------- 4/6 [html5lib]\n",
      "   -------------------------- ------------- 4/6 [html5lib]\n",
      "   -------------------------- ------------- 4/6 [html5lib]\n",
      "   -------------------------- ------------- 4/6 [html5lib]\n",
      "   -------------------------- ------------- 4/6 [html5lib]\n",
      "   --------------------------------- ------ 5/6 [beautifulsoup4]\n",
      "   --------------------------------- ------ 5/6 [beautifulsoup4]\n",
      "   --------------------------------- ------ 5/6 [beautifulsoup4]\n",
      "   --------------------------------- ------ 5/6 [beautifulsoup4]\n",
      "   ---------------------------------------- 6/6 [beautifulsoup4]\n",
      "\n",
      "Successfully installed beautifulsoup4-4.14.3 html5lib-1.1 lxml-6.0.2 soupsieve-2.8 typing-extensions-4.15.0 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies if not already installed\n",
    "!pip install lxml html5lib beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c641e557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "                               Bank Name          City         State   Cert  \\\n",
      "0           The Santa Anna National Bank    Santa Anna         Texas   5520   \n",
      "1                   Pulaski Savings Bank       Chicago      Illinois  28611   \n",
      "2     The First National Bank of Lindsay       Lindsay      Oklahoma   4134   \n",
      "3  Republic First Bank dba Republic Bank  Philadelphia  Pennsylvania  27332   \n",
      "4                          Citizens Bank      Sac City          Iowa   8758   \n",
      "\n",
      "               Acquiring Institution      Closing Date  Fund  Sort ascending  \n",
      "0          Coleman County State Bank     June 27, 2025                 10549  \n",
      "1                    Millennium Bank  January 17, 2025                 10548  \n",
      "2             First Bank & Trust Co.  October 18, 2024                 10547  \n",
      "3  Fulton Bank, National Association    April 26, 2024                 10546  \n",
      "4          Iowa Trust & Savings Bank  November 3, 2023                 10545  \n"
     ]
    }
   ],
   "source": [
    "url_html = 'https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/'\n",
    "df_list = pd.read_html(url_html)\n",
    "print(len(df_list))  # Number of tables found\n",
    "print(df_list[0].head())  # Display first table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e9b8199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   ---------------------------------------- 2/2 [openpyxl]\n",
      "\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "# Install openpyxl for .xlsx files\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f42629",
   "metadata": {},
   "source": [
    "Reading Excel Files\n",
    "Pandas can read Excel files using pd.read_excel(). You can specify the sheet name if the file contains multiple sheets. Reading Excel files requires the openpyxl or xlrd library depending on the Excel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3414b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Statement_id                                              Title  Category  \\\n",
      "0      SIH1524  Innovating for Sustainability: Driving Smart R...  Hardware   \n",
      "1      SIH1525  Innovating for Sustainability: Driving Smart R...  Software   \n",
      "2      SIH1526                                 Student Innovation  Hardware   \n",
      "3      SIH1527                                 Student Innovation  Hardware   \n",
      "4      SIH1528                                 Student Innovation  Hardware   \n",
      "\n",
      "             Technology_Bucket Datasetfile  \\\n",
      "0  Smart Resource Conservation         NaN   \n",
      "1  Smart Resource Conservation         NaN   \n",
      "2              Smart Education         NaN   \n",
      "3          Disaster Management         NaN   \n",
      "4                Miscellaneous         NaN   \n",
      "\n",
      "                                         Description         Department  \\\n",
      "0  Innovating for Sustainability: Driving Smart R...  Godrej Appliances   \n",
      "1  Innovating for Sustainability: Driving Smart R...  Godrej Appliances   \n",
      "2  Smart Education, a Concept that Describes lear...              AICTE   \n",
      "3  Disaster Management includes ideas related to ...              AICTE   \n",
      "4  Technology ideas in tertiary sectors like Hosp...              AICTE   \n",
      "\n",
      "                    Organisation  \n",
      "0              Godrej Appliances  \n",
      "1              Godrej Appliances  \n",
      "2  AICTE, MIC-Student Innovation  \n",
      "3  AICTE, MIC-Student Innovation  \n",
      "4  AICTE, MIC-Student Innovation  \n"
     ]
    }
   ],
   "source": [
    "df_excel = pd.read_excel('SIH_PS_2024.xlsx', sheet_name=0)\n",
    "print(df_excel.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a7a1a",
   "metadata": {},
   "source": [
    "print(df_excel.head())\n",
    "Pickle Files\n",
    "Pickle files serialize Python objects into byte streams for storage or transmission. Pandas supports reading and writing DataFrames to pickle files using to_pickle() and read_pickle() methods. This is useful for saving models or data states in machine learning projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2bf6686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Statement_id                                              Title  Category  \\\n",
      "0      SIH1524  Innovating for Sustainability: Driving Smart R...  Hardware   \n",
      "1      SIH1525  Innovating for Sustainability: Driving Smart R...  Software   \n",
      "2      SIH1526                                 Student Innovation  Hardware   \n",
      "3      SIH1527                                 Student Innovation  Hardware   \n",
      "4      SIH1528                                 Student Innovation  Hardware   \n",
      "\n",
      "             Technology_Bucket Datasetfile  \\\n",
      "0  Smart Resource Conservation         NaN   \n",
      "1  Smart Resource Conservation         NaN   \n",
      "2              Smart Education         NaN   \n",
      "3          Disaster Management         NaN   \n",
      "4                Miscellaneous         NaN   \n",
      "\n",
      "                                         Description         Department  \\\n",
      "0  Innovating for Sustainability: Driving Smart R...  Godrej Appliances   \n",
      "1  Innovating for Sustainability: Driving Smart R...  Godrej Appliances   \n",
      "2  Smart Education, a Concept that Describes lear...              AICTE   \n",
      "3  Disaster Management includes ideas related to ...              AICTE   \n",
      "4  Technology ideas in tertiary sectors like Hosp...              AICTE   \n",
      "\n",
      "                    Organisation  \n",
      "0              Godrej Appliances  \n",
      "1              Godrej Appliances  \n",
      "2  AICTE, MIC-Student Innovation  \n",
      "3  AICTE, MIC-Student Innovation  \n",
      "4  AICTE, MIC-Student Innovation  \n"
     ]
    }
   ],
   "source": [
    "df_excel.to_pickle('data.pkl')\n",
    "df_pickle = pd.read_pickle('data.pkl')\n",
    "print(df_pickle.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cbda6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
